{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d448a72c-7608-4424-9717-3c03a517d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8904c27a-8d28-4934-88a7-5bf92c3ded55",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_abbreviations = {\n",
    "        \"Atlanta Hawks\": \"ATL\", \"Boston Celtics\": \"BOS\", \"Brooklyn Nets\": \"BRK\",\n",
    "        \"Charlotte Hornets\": \"CHO\", \"Chicago Bulls\": \"CHI\", \"Cleveland Cavaliers\": \"CLE\",\n",
    "        \"Dallas Mavericks\": \"DAL\", \"Denver Nuggets\": \"DEN\", \"Detroit Pistons\": \"DET\",\n",
    "        \"Golden State Warriors\": \"GSW\", \"Houston Rockets\": \"HOU\", \"Indiana Pacers\": \"IND\",\n",
    "        \"Los Angeles Clippers\": \"LAC\", \"Los Angeles Lakers\": \"LAL\", \"Memphis Grizzlies\": \"MEM\",\n",
    "        \"Miami Heat\": \"MIA\", \"Milwaukee Bucks\": \"MIL\", \"Minnesota Timberwolves\": \"MIN\",\n",
    "        \"New Orleans Pelicans\": \"NOP\", \"New York Knicks\": \"NYK\", \"Oklahoma City Thunder\": \"OKC\",\n",
    "        \"Orlando Magic\": \"ORL\", \"Philadelphia 76ers\": \"PHI\", \"Phoenix Suns\": \"PHO\",\n",
    "        \"Portland Trail Blazers\": \"POR\", \"Sacramento Kings\": \"SAC\", \"San Antonio Spurs\": \"SAS\",\n",
    "        \"Toronto Raptors\": \"TOR\", \"Utah Jazz\": \"UTA\", \"Washington Wizards\": \"WAS\",\n",
    "        # Historical teams\n",
    "        \"Seattle SuperSonics\": \"SEA\", \"New Orleans Hornets\": \"NOH\", \"Charlotte Bobcats\": \"CHA\",\n",
    "        \"Vancouver Grizzlies\": \"VAN\", \"San Diego Clippers\": \"SDC\", \"Kansas City Kings\": \"KCK\",\n",
    "        \"Washington Bullets\": \"WSB\", \"Buffalo Braves\": \"BUF\", \"New Jersey Nets\": \"NJN\",\n",
    "        \"New Orleans/Oklahoma City Hornets\": \"NOK\", \"St. Louis Hawks\": \"STL\", \n",
    "        \"Syracuse Nationals\": \"SYR\", \"Rochester Royals\": \"ROC\", \"Fort Wayne Pistons\": \"FWP\",\n",
    "        \"Minneapolis Lakers\": \"MNL\", \"Cincinnati Royals\": \"CIN\", \"San Francisco Warriors\": \"SFW\",\n",
    "        \"Philadelphia Warriors\": \"PHW\", \"Chicago Zephyrs\": \"CHZ\", \"Baltimore Bullets\": \"BAL\",\n",
    "        \"Chicago Packers\": \"CHP\", \"Anderson Packers\": \"AND\", \"Sheboygan Red Skins\": \"SRS\",\n",
    "        \"Waterloo Hawks\": \"WAT\", \"Tri-Cities Blackhawks\": \"TRI\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e188bfa-59ee-4320-b5de-2c4fec6e2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stats(total_stats, wins):\n",
    "    \n",
    "    #Clean Wins and merge onto stats,\n",
    "    wins['Team'] = wins['Team'].str.replace('*', '', regex=False)\n",
    "    wins['Team'] = wins['Team'].map(team_abbreviations)\n",
    "    wins = wins[['Rk','Team','W','L']]\n",
    "    total_stats = total_stats.fillna(0)\n",
    "    total_stats.drop(columns=['Rk'], inplace=True)\n",
    "    total_stats = total_stats.merge(wins, left_on='Tm', right_on='Team', how='left')\n",
    "    total_stats.drop(columns=['Team'], inplace=True)\n",
    "    \n",
    "    df = total_stats.copy()\n",
    "    \n",
    "    # Function to calculate weighted values for Rk, W, and L\n",
    "    def calculate_weighted_values(row, total_games):\n",
    "        if pd.notna(row['Rk']):\n",
    "            weighted_rk = (int(row['G']) / total_games) * row['Rk']\n",
    "        else:\n",
    "            weighted_rk = 0\n",
    "        \n",
    "        if pd.notna(row['W']):\n",
    "            weighted_w = (int(row['G']) / total_games) * row['W']\n",
    "        else:\n",
    "            weighted_w = 0\n",
    "            \n",
    "        if pd.notna(row['L']):\n",
    "            weighted_l = (int(row['G']) / total_games) * row['L']\n",
    "        else:\n",
    "            weighted_l = 0\n",
    "        \n",
    "        return weighted_rk, weighted_w, weighted_l\n",
    "    \n",
    "    # Group by 'Player'\n",
    "    for player, group in df.groupby('Player'):\n",
    "        # Find the 'TOT' row\n",
    "        tot_row = group[group['Tm'] == 'TOT']\n",
    "        \n",
    "        # If a 'TOT' row exists\n",
    "        if not tot_row.empty:\n",
    "            # Calculate the weighted Rk, W, L for other rows (not 'TOT')\n",
    "            weighted_values = group[group['Tm'] != 'TOT'].apply(\n",
    "                lambda x: calculate_weighted_values(x, 82), axis=1\n",
    "            )\n",
    "            \n",
    "            # Summing up the weighted values\n",
    "            weighted_rk_sum = weighted_values.apply(lambda x: x[0]).sum()\n",
    "            weighted_w_sum = weighted_values.apply(lambda x: x[1]).sum()\n",
    "            weighted_l_sum = weighted_values.apply(lambda x: x[2]).sum()\n",
    "    \n",
    "            # Set these values to the 'Rk', 'W', 'L' columns of the 'TOT' row\n",
    "            df.loc[tot_row.index, 'Rk'] = weighted_rk_sum\n",
    "            df.loc[tot_row.index, 'W'] = weighted_w_sum\n",
    "            df.loc[tot_row.index, 'L'] = weighted_l_sum\n",
    "    \n",
    "    \n",
    "    has_tot = df[df['Tm'] == 'TOT']['Player'].unique()\n",
    "    \n",
    "    # Filter the DataFrame\n",
    "    # Keep only 'TOT' entries for players who have them\n",
    "    # Keep all entries for players who don't have a 'TOT' entry\n",
    "    df = df[(df['Player'].isin(has_tot) & (df['Tm'] == 'TOT')) | (~df['Player'].isin(has_tot))]\n",
    "    \n",
    "    # Showing the result\n",
    "    total_stats = df.dropna()\n",
    "    \n",
    "    return total_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c639762-0a06-4fbf-aaaf-1315e6b0aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_roy(roy):\n",
    "    roy.columns = [col[1] for col in roy.columns]\n",
    "    return roy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1394a57-bde1-4e54-930f-e501e7c73244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rookies(rookies):\n",
    "    rookies = rookies[['Player','Age', 'G', 'MP', 'FG', 'FGA', '3P',\n",
    "       '3PA', 'FT', 'FTA', 'ORB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
    "       'PTS', 'FG%', '3P%', 'FT%']]\n",
    "    rookies = rookies[~(rookies['Player'].isna() | (rookies['Player'] == 'Player'))]\n",
    "    rookies = rookies.fillna(.000)\n",
    "    return rookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c854fbb7-d204-4b4b-9213-8bf37c33993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv files for: 1977 already exist\n",
      "csv files for: 1978 already exist\n",
      "csv files for: 1979 already exist\n",
      "csv files for: 1980 already exist\n",
      "csv files for: 1981 already exist\n",
      "csv files for: 1982 already exist\n",
      "csv files for: 1983 already exist\n",
      "csv files for: 1984 already exist\n",
      "csv files for: 1985 already exist\n",
      "csv files for: 1986 already exist\n",
      "csv files for: 1987 already exist\n",
      "csv files for: 1988 already exist\n",
      "csv files for: 1989 already exist\n",
      "csv files for: 1990 already exist\n",
      "csv files for: 1991 already exist\n",
      "csv files for: 1992 already exist\n",
      "csv files for: 1993 already exist\n",
      "csv files for: 1994 already exist\n",
      "csv files for: 1995 already exist\n",
      "csv files for: 1996 already exist\n",
      "csv files for: 1997 already exist\n",
      "csv files for: 1998 already exist\n",
      "csv files for: 1999 already exist\n",
      "csv files for: 2000 already exist\n",
      "csv files for: 2001 already exist\n",
      "csv files for: 2002 already exist\n",
      "csv files for: 2003 already exist\n",
      "csv files for: 2004 already exist\n",
      "csv files for: 2005 already exist\n",
      "csv files for: 2006 already exist\n",
      "csv files for: 2007 already exist\n",
      "csv files for: 2008 already exist\n",
      "csv files for: 2009 already exist\n",
      "csv files for: 2010 already exist\n",
      "csv files for: 2011 already exist\n",
      "csv files for: 2012 already exist\n",
      "csv files for: 2013 already exist\n",
      "csv files for: 2014 already exist\n",
      "csv files for: 2015 already exist\n",
      "csv files for: 2016 already exist\n",
      "csv files for: 2017 already exist\n",
      "csv files for: 2018 already exist\n",
      "csv files for: 2019 already exist\n",
      "csv files for: 2020 already exist\n",
      "csv files for: 2021 already exist\n",
      "csv files for: 2022 already exist\n",
      "csv files for: 2023 already exist\n",
      "csv files for: 2024 already exist\n"
     ]
    }
   ],
   "source": [
    "total_stats_dfs = []\n",
    "mvp_dfs = []\n",
    "roy_dfs = []\n",
    "rookies_dfs = []\n",
    "\n",
    "years = range(1977, 2025)\n",
    "\n",
    "for year in years:\n",
    "    if (os.path.exists(f'stats_{year}.csv') and os.path.exists(f'mvp_{year}.csv') and os.path.exists(f'roy_{year}.csv') and os.path.exists(f'rookies_{year}.csv')):\n",
    "        print(\"csv files for:\", year, \"already exist\")\n",
    "    else:\n",
    "        stats_url = f'https://www.basketball-reference.com/leagues/NBA_{year}_totals.html'\n",
    "        wins_url = f'https://www.basketball-reference.com/leagues/NBA_{year}.html'\n",
    "        awards_url = f'https://www.basketball-reference.com/awards/awards_{year}.html'\n",
    "        rookie_url = f'https://www.basketball-reference.com/leagues/NBA_{year}_rookies-season-stats.html'\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "        }\n",
    "        \n",
    "        stats_response = requests.get(stats_url, headers=headers)\n",
    "        wins_response = requests.get(wins_url, headers=headers)\n",
    "        awards_response = requests.get(awards_url, headers=headers)\n",
    "        rookie_response = requests.get(rookie_url, headers=headers)\n",
    "        \n",
    "        if stats_response.status_code == 200 and wins_response.status_code == 200 and awards_response.status_code == 200 and rookie_response.status_code == 200:\n",
    "            print(\"Successfully fetched the pages for:\", year)\n",
    "            \n",
    "            stats_html = BeautifulSoup(stats_response.text, \"html.parser\")\n",
    "            wins_html = BeautifulSoup(wins_response.text, \"html.parser\")\n",
    "            wins_html.find('tr', class_=\"over_header\").decompose()\n",
    "            awards_html = BeautifulSoup(awards_response.text, \"html.parser\")\n",
    "            awards_html.find('tr', class_=\"over_header\").decompose()\n",
    "            rookie_html = BeautifulSoup(rookie_response.text, \"html.parser\")\n",
    "            rookie_html.find('tr', class_=\"over_header\").decompose()\n",
    "\n",
    "            stats_raw = str(stats_html.find(id=\"totals_stats\"))\n",
    "            wins_raw = str(wins_html.find(id=\"advanced-team\"))\n",
    "            mvp_raw = str(awards_html.find(id=\"mvp\"))\n",
    "            roy_raw = str(awards_html.find(id=\"roy\"))\n",
    "            rookie_raw = str(rookie_html.find(id=\"rookies\"))\n",
    "            #dpoy_raw = str(awards_html.find(id=\"dpoy\"))\n",
    "            #smoy_raw = str(awards_html.find(id=\"smoy\"))\n",
    "            #mip_raw = str(awards_html.find(id=\"mip\"))\n",
    "            \n",
    "            # Now, pass this file-like object to pd.read_html()\n",
    "            total_stats = pd.read_html(StringIO(stats_raw))[0]\n",
    "            wins = pd.read_html(StringIO(wins_raw))[0]\n",
    "            mvp = pd.read_html(StringIO(mvp_raw))[0]\n",
    "            roy = pd.read_html(StringIO(roy_raw))[0]\n",
    "            rookies = pd.read_html(StringIO(rookie_raw))[0]\n",
    "            #dpoy = pd.read_html(StringIO(dpoy_raw))[0]\n",
    "            #smoy = pd.read_html(StringIO(smoy_raw))[0]\n",
    "            #mip = pd.read_html(StringIO(mip_raw))[0]\n",
    "        \n",
    "            total_stats = clean_stats(total_stats, wins)\n",
    "            roy = clean_roy(roy)\n",
    "            rookies = clean_rookies(rookies)\n",
    "            total_stats_dfs.append(total_stats)\n",
    "            mvp_dfs.append(mvp)\n",
    "            roy_dfs.append(roy)\n",
    "            rookies_dfs.append(rookies)\n",
    "    \n",
    "            total_stats.to_csv(f'stats_{year}.csv', index=False)\n",
    "            mvp.to_csv(f'mvp_{year}.csv', index=False)\n",
    "            roy.to_csv(f'roy_{year}.csv', index=False)\n",
    "            rookies.to_csv(f'rookies_{year}.csv', index=False)\n",
    "        elif stats_response.status_code == 429 or wins_response.status_code == 429 or awards_response.status_code == 429 or rookie_response.status_code == 429:\n",
    "            retry_after = int(stats_response.headers.get('Retry-After', 30))  # Default to 30 seconds if header is missing\n",
    "            print(f\"Rate limit exceeded. Waiting for {retry_after} seconds.\")\n",
    "            time.sleep(retry_after)\n",
    "        else:\n",
    "            print(\"Failed to fetch the page, stats status code:\", stats_response.status_code, \"for year:\", year)\n",
    "            print(\"Failed to fetch the page, wins status code:\", wins_response.status_code, \"for year:\", year)\n",
    "            print(\"Failed to fetch the page, awards status code:\", awards_response.status_code, \"for year:\", year)\n",
    "            print(\"Failed to fetch the page, rookies status code:\", rookie_response.status_code, \"for year:\", year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
